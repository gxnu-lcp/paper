# DSOS: A Distributed Secure Outsourcing System for Edge Computing Service in IoT

**Abstract:**

Edge computing can help the resource-constrained Internet of Things (IoT) devices to perform some complex tasks. Edge computing has many advantages, such as the distributed architecture, low interaction latency, and good resilience. It can provide fast response and reliable service for the IoT applications. There exists an important application in the edge computing environment is to outsource the computationally intensive problems to nearby edge servers, which has become a research hotspot in the area of industry and academia. In this article, we propose a distributed and secure system DSOS for seeking the least squares solution to the overdetermined system of linear equations (OSLE) with the assistance of multiple nearby noncolluding edge servers. Solving this type of linear equations is one of the most common problems for statistics and data mining in IoT. In our system, the coefficient matrix is divided into multiple blocks according to rows. The different blocks are distributed to the different edge servers. All edge servers can help the user to obtain the correct solution to the OSLE by the interactive computation. Our system can ensure the private information about input parameters and final results is not leaked to the participating edge servers. In addition, the mutual verification between the edge servers can ensure the validity of the final results. The experimental evaluations show that the designed system outperforms the existing ones in terms of fast response between the edge server and the user, low computation overload on the edge server side, and high efficiency on the user side.

## Introduction

Internet of Things (IoT) is an intelligent communication paradigm, which can connect some physical devices to the Internet to carry out data collection [1] and data exchange [2] by the network protocols. IoT, which contributes to improving the quality of life and promoting the development of medical industry [3], is the extension of the traditional Internet-based network. With the proliferation of IoT, there is a prediction [4] that more than 79.4-ZB data will be produced by the IoT devices in 2025. However, due to the limitation of storage space and computation power, it is hard for IoT devices to deal with such large-scale data. Although the IoT devices can outsource data to a centralized cloud server to store and compute [5], [6], there is the high service latency because of the long distance transmission between the cloud center and the user, which is hard to meet the real-time requirement of IoT devices. With the development of edge computing, a large amount of data generated by various IoT devices can be promptly processed by the network edge instead of a centralized cloud server. As a result, a lot of IoT applications based on edge computing appear.

Compared with cloud computing, outsourcing computation based on edge computing has more comprehensive applications. However, it also faces a series of challenges. First, since the edge servers may be not trusted by the user, the user should protect input and output from being leaked to the participating edge servers. Second, the edge servers may behave dishonestly for various reasons, such as saving computation resources, being compromised by attackers, and making mistake due to software bugs. How to ensure the correctness of the result returned from edge servers is another challenge. Third, an outsourcing system based on multiple edge servers needs all edge servers to collaboratively work toward solving the computation task. How to ensure multiple edge servers securely and correctly compute the final result also is a challenge. At last, the local computation complexity of the user, involved in this kind of secure outsourcing, should be much lower than that of locally solving the original problem by the user.

For the overdetermined system of linear equation (OSLE) $Ax=b$, where $A$ is an $(r\times n)$-dimensional ( $r > n$) coefficient matrix and $b$ is an $r$-dimensional constant column vector, there is usually no exact solution. Therefore, finding an approximate solution to the OSLE becomes a meaningful problem. How to seek a least squares solution to the large-scale OSLE is widely applied in various engineering and scientific computations in the real world, such as wireless localization [7], weather forecasts [8], harmonics estimation in power systems [9], etc. There are some distributed algorithms for solving the OSLE problem, including continuous-time algorithms [10] and discrete-time algorithms [11], [12]. These distributed algorithms usually decompose the large-scale linear equations into multiple small-scale linear equations to improve efficiency. Each agent only knows one or multiple rows of the matrix $A$ and the vector $b$. These agents can get the final result by the interactive computation. But these distributed algorithms are not applicable for the IoT devices. In addition, there exist some methods for solving the OSLE, such as QR decomposition and SVD decomposition. The computation complexity is more than $O(r^{3})$ and the storage complexity is more than $O(r\times n)$. When the scale of the matrix is too large, for example, a matrix contains tens of thousands of rows and columns, it is difficult for some IoT devices to carry out this task. In order to solve the OSLE for the IoT devices, some secure outsourcing systems [13], [14] have been proposed. The main idea of these systems is that the resource-constrained devices outsource some complex computations to a powerful and centralized cloud server. But these systems are not applicable in the edge computing scenario. Different from the traditional cloud computing, edge computing can allow multiple edge servers who have lower computation and storage resources than a cloud server, to collaboratively carry out the computation tasks. If the computation tasks are delegated to one edge server, the server may take longer time to complete them. We design a secure and distributed system DSOS for seeking a least squares solution to the OSLE problem. DSOS combines distributed computation and secure outsourcing computation, which can simultaneously reduce the computation overhead on the user side and the edge server side. DSOS utilizes the carefully designed matrices to protect the privacy of input and output. In addition, DSOS does not require the user to verify the correctness of the returned result, but utilizes the mutual verification among the edge servers, which further decreases the computation overhead on the user side.

We summarize the main contributions of this article as three folds.

1. Based on edge computing, we design a distributed and privacy-preserving system DSOS to solve the large-scale OSLE problem.
2. We design a novel detection algorithm to ensure the validity of the returned result. The validity of result and the detection of the malicious behavior can be carried out among the edge servers.
3. Through the theoretical analysis, it shows that the proposed system can satisfy our design goals. We also conduct experiments to prove the proposed system is efficient on the user side and the edge server side.



The remainder of this article is organized as follows. More related work is reviewed in Section II. Section III describes system model and design goals. Some mathematical definitions and preliminaries about a distributed algorithm for the OSLE problem are given in Section IV. The framework and description of the proposed system DSOS are given in Section V. The theoretical performance analysis is also given in this section. In Section VI, we give the experimental evaluation and the engineering application of the proposed system DSOS. Section VII concludes this article.

SECTION II.

## Related Work

There are much related research on edge computing, distributed algorithms for OSLE, secure outsourcing computation, and outsourcing systems for the system of linear equations.

### A. Edge Computing

Shi *et al.* [15] gave a concept about edge computing and researched several practical applications of edge computing. Yu *et al.* [16] comprehensively analyzed the edge computing’s improvement to the property of IoT networks. In addition, the authors proposed a framework to evaluate the security of IoT network and put forward some security issues in the edge computing environment. Pan and McElhannon [17] introduced the key rationales and technologies for edge computing. They discussed some typical IoT applications based on edge computing. Kang *et al.* [18] discussed how to securely store and share data by combining edge computing and blockchain.

### B. Distributed Algorithms for OSLE

Under a connected and fixed agent network, Pasqualetti *et al.* [11] put forward a discrete-time distributed algorithm for solving the OSLE problem. In their algorithm, each agent could choose an initial estimate of $x$ and transmit the estimate of $x$ in subsequent iterations. Mou *et al.* [12] designed a distributed algorithm for the system of linear equations, which converged to a solution exponentially fast. In their algorithm, each agent could generate a sequence of estimates according to some necessary and sufficient conditions. Anderson *et al.* [10] first proposed a continuous-time distributed algorithm by using a projected consensus method. Their algorithm could achieve the linear convergence rate.

### C. Secure Outsourcing Computation

Many researchers have proposed different kinds of secure outsourcing systems for the cryptographic computations [19]–[21] and the large-scale scientific computations [22]–[26].

There are many secure outsourcing systems about the cryptographic computations. Hohenberger and Lysyanskaya [19] provided the formal security definition about how to securely outsource cryptographic computations and put forward two outsource-secure encryption systems for Schnorr signature and Cramer–Shoup encryption. Tian *et al.* [20] realized the secure outsourcing of modular inversion by designing a novel unimodular matrix transformation technique. Li *et al.* [21] considered how to securely outsource exponentiation operation to multiple untrusted edge servers. In their system, a large exponent could be decomposed into multiple smaller exponents for computation.

The large-scale scientific computations, including matrix operation, system of linear equations, mathematical optimization task and graph problem, etc., usually contain some sensitive information and complicated computations. Especially, with the arrival of big data, the size of data in the scientific computations becomes larger and larger. For some specific scientific computations, many researchers have proposed some different secure outsourcing systems. For example, a generic framework about how to securely outsource the scientific computations was designed by Atallah *et al.* [22]. However, the misbehavior of the server could not be detected by the user. Based on an untrusted cloud server, Wang *et al.* [23] researched how to securely outsource the linear programming problem. While protecting the confidentiality of data, their system could verify the validity of the returned result by adopting the duality of linear programming. Lei *et al.* [24] studied how to securely and efficiently outsource the matrix inversion computation. The large-scale linear system of equations (LSE) could be solved by this system. Based on the different cloud computing models, Zhao *et al.* [25] proposed two systems for securely finding a mincut of the undirected edge-weighted graphs.

### D. Secure Outsourcing Systems for Linear System of Equations

LSE, as one of the commonly used operations in engineering, has been extensively studied by many researchers. Wang *et al.* [27] studied how to securely solve a large-scale LSE based on cloud computing. In this article, the user could solve the LSE problem by the Jacobi method and preserve privacy by the homomorphic encryption. Salinas *et al.* [28] studied how to efficiently and securely solve the large-scale LSE problem based on the conjugate gradient method. Although their system had the low computation and memory I/O complexities, but it required multiple-round communication. Based on a malicious cloud server, Chen *et al.* [29] proposed a secure outsourcing system for the large-scale LSE by utilizing the sparse matrix. The user needed to communicate with the cloud server only once and could verify the validity of the returned result with the probability 1. Yu *et al.* [30] designed a noniterative and secure outsourcing system for the large-scale LSE. In their system, the user could utilize some carefully designed random matrices to hide the number and position of zero elements in the coefficient matrix. Nie *et al.* [13] designed a secure outsourcing system for the LSE problem. When the malicious cloud server argued that there was no solution to the LSE problem, the user could detect the misbehavior of the server by using a verifiable algorithm based on linear programming. These existing systems focus on outsourcing the LSE problem to a centralized cloud server. Pan *et al.* [14] studied how to securely outsource the large-scale OSLE problem to a cloud server by utilizing the QR decomposition. Recently, Shen *et al.* [31] proposed a distributed and secure outsourcing system, which allowed the user to outsource the LSE to multiple ad hoc clouds.

In short, our research is different from all previous ones. In this article, we first consider how to securely seek the least squares solution to the OSLE based on multiple noncollusion edge servers. On the one hand, how to design more distributed and secure outsourcing systems for other complex and large-scale computations is worth being considered in the future research. On the other hand, how to design a verification algorithm to resist collusion attack is a worthy topic.

SECTION III.

## System Model, Definition, and Design Goals

First, we give a specific description about the system model and some definitions. In addition, we describe the threat model and design goals. There are the mainly used notations in Table I.

**TABLE I** Notations

[![Table I-  Notations](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu.t1-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu.t1-3179345-large.gif)



### A. System Model

The privacy-preserving and distributed outsourcing system DSOS contains two entities, as depicted in Fig. 1. The user with the low computation capability wants to delegate a complex computation task $F$ to multiple edge servers who have the powerful computation resources. But the edge servers are not fully trusted by the user. To preserve privacy, the user utilizes the secret key $SK$ to encrypt the original input $X$ into the encrypted one $X'$ and divides the encrypted input $X'$ into multiple inputs { $X'_{1}, X'_{2},\ldots, X'_{i},\ldots, X'_{m}$}. The user distributes each input to each edge server and its neighbor servers. For example, the input $X'_{i}$ will be sent to the edge server $i$ and $i'\text{s}$ neighbor servers. Each edge server carries out a series of iterative computations. Its neighbor servers verify the correctness of results according to the received data. When the distributed consensus algorithm achieves a final convergent $Y'$, the result $Y'$ is a solution to the encrypted $F(X')$. The user decrypts the returned result $Y'$ by using the secret key $SK$ and gets the result $Y$ for the original task $F(X)$.

[![Fig. 1. - System model.](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu1-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu1-3179345-large.gif)

**Fig. 1.**

System model.

[Show All](https://ieeexplore.ieee.org/document/9791077/figures)



The user, who is with the limited computation resources, has a large-scale OSLE task to solve. There are multiple edge servers, who perform certain computation tasks within their computation capability. If this computation task is delegated to one edge server, the server may take more time to complete it. So, multiple edge servers cooperate with each other to solve this computation task, which takes less time. We assume the connection relationship of edge servers is known by the user. The user can run a secure neighbor discovery algorithm [32] before outsourcing this computation task to the edge servers. We consider the static network topology. It means that the connection relationship of edge servers will not change in the process of solving the OSLE. There is an OSLE problem $Ax=b$, where $A\in \mathbb {R}^{r\times n} (r > n)$ is a constant matrix, $b\in \mathbb {R}^{r\times 1}$ is a constant column vector, and $x \in \mathbb {R}^{n\times 1} $ is the unknown variable. In most instances, the OSLE has no exact solution. Finding a least squares solution to the OSLE problem becomes very meaningful. The complexity of computing a least squares solution to the OSLE based on a cloud server is more than $O(r^{3})$. Since the user is lack of computation powers, the user is hard to complete such intensive computation by itself. But the user can solve the OSLE task with the assistance of edge servers. All edge servers are willing to share their computation resources by a pay-per-use manner and can collaboratively work to securely solve this OSLE problem.



#### Remark 1:

Our system model is different from some system models based on multiple cloud servers. In some systems, in order to ensure the validity of result, the user outsources the computation task to multiple cloud servers and combines the returned results from multiple cloud servers. In this article, the user outsources the computation task to multiple edge servers, which lets the user get the faster response and decreases the computation overhead on each edge server side.





#### Remark 2:

Improving the efficiency of user and protecting the user’s private data is the main purpose of DSOS. Our system model only considers how much data are transmitted in process of offloading task to the servers as well as exchanging messages among different servers. We do not take the other communication costs into consideration, such as the latency for exchanging the messages and the associated energy consumption. This is the same with that in the related works [14], [21], [31].



### B. Framework

Syntactically, the following six subalgorithms compose a distributed secure outsourcing system DSOS.

1. *KeyGen(* $F, X, \lambda $ *)* $\rightarrow SK$ *:* Given a security parameter $\lambda $ and the computation task $F$ with an input $X$, the key generation algorithm produces a private key $SK$.
2. *ProbEnc(* $F, SK, X$ *)* $\rightarrow X'$ *:* Given the description of computation task $F$, this algorithm encrypts the input $X$ into a blinded value $X'$ by utilizing the secret key $SK$.
3. *ProbSplit(* $X', m$ *)* $\rightarrow $ *{* $X'_{1}, X'_{2},\ldots, X'_{i},\ldots, X'_{m}$ *}:* The encrypted input $X'$ is divided into $m$ parts by the user. The user distributes each input $X'_{i}$ to the corresponding edge server $i$ and its neighbor servers, where $i\in [1,m]$.
4. *ProbCom(* $F,X'_{i},{(}Y'_{i}{)}^{k-\textit {1}}$ *)* $\rightarrow {\{{(}Y'_{i}{)}^{k},Y'\}}\textit {}$ *:* At $k$ iteration, according to the given computation task $F$, the corresponding input $X'_{i}$, and the result of last iteration $(Y'_{i})^{k-1}$, each edge server $i$ computes the temporary result $(Y'_{i})^{k}$, and iteratively derives the final result $Y'$.
5. *ProbVer(* $F,X'_{i},{(}Y'_{i}{)}^{k-\textit {1}},{(}Y'_{i}{)}^{k}$ *)* $\rightarrow {\{\textit {0, 1\}}}$ *:* At $k$ iteration, given $(Y'_{i})^{k-1}$ and $(Y'_{i})^{k}$, $i's$ neighbor servers verify the correctness of $(Y'_{i})^{k}$ by using $X'_{i}$ and $F$. If the result $(Y'_{i})^{k}$ passes verification successfully, this algorithm outputs 1; otherwise, this algorithm outputs 0.
6. *ResultDec(* $F,SK,X,Y'$ *)* $\rightarrow Y$ *:* Given the final result $Y'$ and the private key $SK$, the user runs this algorithm to get the desired result $Y=F(X)$.



At each iteration, each edge server $i$ transmits the temporary result $(Y'_{i})^{k}$ to its neighbor servers. If all temporary results pass verification successfully, all edge servers continue to carry out the next iteration; otherwise, the malicious edge servers will be kicked out and the user again sends the corresponding computation tasks to the remaining edge servers.

### C. Security Requirements

There are some security requirements of the distributed secure outsourcing system.

Correctness is the first requirement of outsourcing computation. An outsourcing system is correct if, for any honest edge server and any valid input $X$, it outputs the desired value $Y=F(X)$. More formally, it is as follows.



#### Definition 1 (Correctness):

A distributed secure outsourcing system is correct if for any computation task $F$, the key generation algorithm produces key $SK \leftarrow $**KeyGen(** $F, X, \lambda $**)**, such that $\forall X \in $ **Domain(** $F$**)**, if $X'\leftarrow $ **ProbEnc(** $F, SK, X$**)**, { $X'_{1}, X'_{2},\ldots, X'_{i},\ldots, X'_{m}$} $\leftarrow $ **ProbSplit(** $X', m$**)**, $\{(Y'_{i})^{k},Y'\}\leftarrow $ **ProbCom(** $F,X'_{i},(Y'_{i})^{k-1}$**)**, and $1 \leftarrow $ **ProbVer**( $F,X'_{i},(Y'_{i})^{k-1},(Y'_{i})^{k}$), then $Y=F(X)\leftarrow $ **ResultDec**( $F,SK,X,Y'$).



The privacy of input and output for computation task is the second requirement. It means that any sensitive information in the execution of outsourcing system should not be disclosed to the edge servers.



#### Definition 2 (Privacy):

Given a security parameter $\lambda $, for a secure outsourcing system Alg, it can protect the privacy of input if for any probabilistic polynomial time (PPT) adversary $A$ $$\begin{equation*} {\mathrm{ Adv}}^{\mathrm{ Alg}}_{A}(F,\lambda)\leq {\mathrm{ negli}}(\lambda)\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)where ${\mathrm{ negli}}()$ is a negligible function of its input, and we denote ${\mathrm{ Adv}}^{\mathrm{ Alg}}_{A}(F,\lambda)=|Pr[t=t']-(1/2)|$ as the advantage of $A$ in the experiment $$\begin{align*}&{\mathrm{ Experiment}} \quad \textbf {EXP}^{\textbf {Priv}}[F,\lambda]\\&SK \leftarrow \textbf {KeyGen}(F,\lambda);\\&(X_{0},X_{1})\leftarrow \textbf {A}^{\textbf {PubProbEnc(.)}}(F);\\&X'_{0}\leftarrow \textbf {ProbEnc}(F,SK,X_{0});\\&X'_{1}\leftarrow \textbf {ProbEnc}(F,SK,X_{1});\\&t\leftarrow \{0,1\};\\&t' \leftarrow \textbf {A}^{\textbf {PubProbEnc(.)}}\left ({F,X_{0},X_{1},X'_{t}}\right).\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)



In the above experiment, adversary $A$ is given the computation task $F$ and selects two inputs $X_{0}$ and $X_{1}$. He must guess which one is encoded based on the given encoding of a randomly selected one of the two inputs. The adversary $A$ can request the encoding of any inputs. The oracle **PubProbEnc(** $F,SK,X$**)** calls **ProbEnc**( $F,SK,X$) to obtain the public value $X'$. The encoding of input in **PubProbEnc(** $F,SK,X$**)** oracle must be probabilistic.

A similar definition can be given for the privacy of output.

The final condition we require is efficiency. The time cost on the user side, including the encryption of input and decryption of output, must be smaller than the time cost of solving the computation task $F$ locally.



#### Definition 3 ( *$\alpha $*-Efficiency):

A distributed secure outsourcing system Alg is said to be an $\alpha $-efficiency implementation of $F$ if: 1) it is an outsource-secure implementation of $F$ and 2) $\forall $ inputs $X$, the running time on the user side is an $\alpha $-multiplicative factor of the running time of $F(X)$.



### D. Threat Model And Design Goals

It is hard for the user to find the fully trusted edge servers in practical application. Some edge servers may behave maliciously for a variety of reasons, such as saving computation resources, being attacked by hacker and existing software bugs, etc. These malicious edge servers may prob some sensitive information that the user is not willing to disclose to the edge servers in process of solving the OSLE task, and may return the incorrect result. For an edge server, we assume that there are more honest neighbor servers than the malicious ones. We further assume that these malicious edge servers are noncolluding. We can specify the malicious behavior into the following categories based on their motivations.

1. Different servers are assigned with some different subtasks. These subtasks may contain some confidential information, which cannot be leaked to the edge servers. When the iterative computation is completed, all edge servers jointly help the user to obtain a final solution to the original task, which is not derived by the edge servers. Therefore, before the original task is sent to the edge servers, the user should blind the original task and ensure the edge servers cannot obtain any knowledge about the solution to the original task.
2. When running the consensus-based distributed algorithm, each edge server repeatedly carries out the iterative computation. The results of each iteration affect the final result. One malicious edge server may continuously inject a false intermediate result in process of iteration. This malicious behavior may lead to a false solution to the original task or diverge the consensus (iterative process does not stop).

Therefore, a trick for designing the distributed secure outsourcing system is how to verify the validity of the intermediate results from each edge server in process of the iterative computation.



According to the above analysis, the outsourcing system DSOS should realize the following goals.

1. *Correctness:* The user will obtain the correct result of the original OSLE while the user and all edge servers honestly follow the outsourcing system.
2. *Privacy:* The edge servers cannot obtain any knowledge about the user’s sensitive information during running the outsourcing system. On the one hand, the privacy of input means that any meaningful knowledge about the user’s input data should not be disclosed to the edge servers. On the other hand, the privacy of output means that the correct result of the original OSLE should not be leaked to the edge servers.
3. *Misbehavior Detection:* In the process of the iterative computation, some edge servers may broadcast the incorrect results to their neighbor servers. This misbehavior should be detected with a high probability. Relatively, the correct results from these honest edge servers should be verified successfully. The outsourcing system should guarantee the validation of the final result.
4. *Efficiency:* On the one hand, the computation complexity invested by the user is substantially smaller than that of performing the original task by itself. On the other hand, the computation burden on each edge server side should be less than that of solving the original task only based on one server.



SECTION IV.

## Basic Functions and OSLE

### A. Random Permutation Function

A random permutation means that all elements of a set are rearranged into a random order. There is good research on the random permutation function in combinatorics and group theory [33]. We can express a random permutation as $$\begin{align*} \left ({\begin{array}{ccc} 1 &~~ \cdots &~~ s \\ p_{1} &~~ \cdots &~~ p_{s} \\ \end{array} }\right).\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

We denote it by using a random permutation function $\pi (i)=p_{i}$, where $i=1,\ldots, s$. The inverse function of $\pi $ is denoted as $\pi ^{-1}$. We describe the generation of random permutation $\pi _{1}$ and $\pi _{2}$ as follows.

### B. Key Matrix

Define the Kronecker delta function $\sigma _{x,y}$ as follows: $$\begin{align*} \sigma _{x,y} = \left \{{ \begin{array}{ll} 1, &~x=y \\ 0, &~x\neq y \end{array}. }\right.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

We can construct the key matrix $P$ by Algorithm 1 and the Kronecker delta function. First, we pick a set of numbers $\alpha _{1},\ldots, \alpha _{r}$ from the set $\Omega =\{1,-1\}$. Then, we construct the key matrix $P$ according to the following equations: $$\begin{equation*} P(i,j)=\alpha _{i}\sigma _{\pi (i),j},\quad 1\leq i,j\leq r.\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

### Algorithm 1 Random Permutation Generation

Input:

$r$and $n$, the number of row and column.

Output:

Two random permutations $\pi _{1}$ and $\pi _{2}$.

1:

Initialize $\pi _{1}$ as: $$\left ({\begin{array}{ccc} {1} &{~~{...}} &{~~\text{ r}} \\ {1} &{~~{...}} &{~~\text{ r}} \\{}\end{array}}\right).$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

2:

**for** $i=r$ down to 2 **do**

3:

$j$ is a random integer where $1\leq j\leq i$;

4:

Swap $\pi (i)$ and $\pi (j)$;

5:

**end for**

6:

$\pi _{2}$ is obtained by repeating line 1 to line 5.

7:

**return** $\pi _{1}$ and $\pi _{2}$.



There exists only one element in each row and column of the key matrix $P$ unequal to 0. Note that the key matrix $P$ is the orthogonal matrix because every column of matrix $P$ is perpendicular and normalized. It means $P^{T}=P^{-1}$. For example, we set $r=4$ and choose a random permutation $$\begin{align*} \left ({\begin{array}{cccccc} 1&~~ 2&~~ 3&~~ 4 \\ 3&~~ 4&~~ 1&~~ 2 \\ \end{array} }\right).\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

We denote $\alpha _{1}=\alpha _{2}=1$ and $\alpha _{3}=\alpha _{4}=-1$. So, the key matrix can be expressed as follows: $$\begin{align*} \begin{bmatrix} 0 &~~ 0 &~~ 1 &~~ 0 \\ 0 &~~ 0 &~~ 0 &~~ 1 \\ -1 &~~ 0 &~~ 0 &~~ 0 \\ 0 &~~ -1 &~~ 0 &~~ 0 \end{bmatrix}.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)$P^{T}$ and $P^{-1}$ can be expressed as follows: $$\begin{align*} \begin{bmatrix} 0 &~~ 0 &~~ -1 &~~ 0 \\ 0 &~~ 0 &~~ 0 &~~ -1 \\ 1 &~~ 0 &~~ 0 &~~ 0 \\ 0 &~~ 1 &~~ 0 &~~ 0 \end{bmatrix}.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

### C. Overdetermined System of Linear Equations

The system of linear equations is as follows: $$\begin{equation*} Ax=b\tag{1}\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)where $A\in \mathbb {R}^{r\times n}$, $b\in \mathbb {R}^{r\times 1}$, and $x \in \mathbb {R}^{n\times 1} $. When $r > n$ (the number of equations is greater than the number of unknown variables), the system of linear equations is called the OSLE. ${\mathrm{ Rank}}(A)$ is denoted as the rank of $A$. About the solution to [(1)](https://ieeexplore.ieee.org/document/#deqn1), there are three cases as follows.

1. [Equation (1)](https://ieeexplore.ieee.org/document/#deqn1) has no exact solution when ${\mathrm{ rank}}(A,b)\neq {\mathrm{ rank}}(A) $.
2. [Equation (1)](https://ieeexplore.ieee.org/document/#deqn1) has only one exact solution when ${\mathrm{ rank}}(A,b)={\mathrm{ rank}}(A)=n$.
3. [Equation (1)](https://ieeexplore.ieee.org/document/#deqn1) has endless exact solutions when ${\mathrm{ rank}}(A,b)={\mathrm{ rank}}(A) < n$.

From the above discussion, we can know that there may be no exact solution to [(1)](https://ieeexplore.ieee.org/document/#deqn1). But there is always a least squares solution to [(1)](https://ieeexplore.ieee.org/document/#deqn1). Moreover, a least squares solution is also an exact solution when [(1)](https://ieeexplore.ieee.org/document/#deqn1) exists one or multiple exact solutions. We can define a least squares solution to [(1)](https://ieeexplore.ieee.org/document/#deqn1) as follows.



A least squares solution to [(1)](https://ieeexplore.ieee.org/document/#deqn1) is a solution to the optimization problem $\min _{x}|Ax-b|^{2}_{2}$. Furthermore, denote $| |_{2}$ as the 2-norm. For example, we define the 2-norm of a vector $a \in \mathbb {R}^{n\times 1}$ as $|a|_{2}= \sqrt {\sum _{i=1}^{n}(a_{i}^{2})}$. Note that the following equation must hold when $x$ is a least squares solution to [(1)](https://ieeexplore.ieee.org/document/#deqn1). We denote $A^{T}$ as the transpose of $A$ $$\begin{equation*} A^{T}Ax=A^{T}b.\tag{2}\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

### D. Preliminaries on Distributively Solving OSLE

We adopt a distributed technique proposed in [34] to allow the edge servers to cooperatively solve the OSLE problem. The original problem can be decomposed into multiple subproblems, which can be solved by the edge servers within their computation powers, respectively. The consensus-based distributed technique can be summarized as follows.

Based on a multiagent network, the authors proposed a distributed technique for seeking a least squares solution to $Ax=b$. We assume there are $m$ edge servers to seek a least squares solution $x\in \mathbb {R}^{n\times 1}$. We can decompose the matrix $A$ into $m$ row-blocks matrices and the vector $b$ into $m$ row-blocks vectors $$\begin{align*} A=\begin{bmatrix} A_{1}\\ A_{2}\\ \vdots \\ A_{m} \end{bmatrix},\quad b=\begin{bmatrix} b_{1}\\ b_{2}\\ \vdots \\ b_{m} \end{bmatrix}.\tag{3}\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

Let $A_{i}$ and $b_{i}$ be the $i$th row-block, where $A_{i}\in \mathbb {R}^{r_{i}\times n}$ and $b_{i} \in \mathbb {R}^{r_{i}\times 1}$. We denote $r_{i}=[r/m]$, where $i\in [{1,m-1}]$ and $r_{m}=r-r_{i}\times (m-1)$. Each edge server $i$ only knows $A_{i}$ and $b_{i}$, where $A_{i}x=b_{i}$. Solving a least squares solution $x$ is equal to seeking a solution to the optimization problem as follows: $$\begin{equation*} x={\mathrm{ arg}} \min _{x\in \mathbb {R}^{n\times 1}} \frac {1}{2}\sum _{i=1}^{m}\left |{A_{i}x-b_{i}}\right |^{2}_{2}.\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

Note that if other edge servers can communicate with the edge server $i$, these edge servers are viewed as $i$’s neighbors. The communication between any two edge servers is bilateral, which means that the edge server $i$ can transmit messages to the edge server $j$ and the edge server $j$ also can transmit messages to the edge server $i$. The edge server $i$ can communicate with itself. In order to start the distributed computation, each edge server chooses an initial estimation of $x$, including $x_{i}(0)$ and $z_{i}(0)$, $i \in [1,2,\ldots, m]$, where $z \in \mathbb {R}^{n\times 1}$ is an auxiliary variable. Each edge server needs to control two state vectors $x_{i}$ and $z_{i}$ in each iteration process. According to an updating rule, each edge server iteratively updates its estimation. The distributed technique can achieve an exponential convergence rate. The update process can be expressed as $$\begin{align*} \begin{bmatrix} x_{i}(t+1)\\ z _{i}(t+1)\end{bmatrix}=F_{i}^{-1}\begin{bmatrix}d_{i}x_{i}(t)+\Sigma _{j \in \mathcal {N}_{i}} { w_{ij}z_{j}(t)}+cA^{T}_{i}b_{i}\\ -\Sigma _{j \in \mathcal {N}_{i}} { w_{ij}x_{j}(t)}+d_{i}z_{i}(t)\end{bmatrix}\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)where $$\begin{align*} F_{i}=\begin{bmatrix}d_{i}I_{n}+cA^{T}_{i}A_{i}&~~ d_{i}I_{n}\\ -d_{i}I_{n}&~~ d_{i}I_{n} \end{bmatrix}.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

The weight between the server $i$ and the server $j$ is $w_{i,j}$. If $j \in \mathcal {N}_{i}$, set $w_{i,j}=1$; otherwise, set $w_{i,j}=0$. $c$ is an arbitrary positive constant. In this article, we set $c=1$. $\mathcal {N}_{i}$ is the set of $i$’s neighbor servers and $d_{i}$ is the number of $i$’s neighbor servers.

In order to speed up computation, we can compute the inverse of $F_{i}$ according to the following formula: $$\begin{align*} F^{-1}_{i}=&-\frac {1}{4d_{i}^{2}}\begin{bmatrix}I_{n}\\ I _{n}\end{bmatrix}A^{T}_{i} \left ({\frac {1}{c}I_{n_{i}}+\frac {1}{2d_{i}}A_{i}A^{T}_{i}}\right)^{-1}A_{i} \begin{bmatrix} I_{n}&~~ I_{n}\end{bmatrix} \\&+\,\,\frac {1}{2d_{i}}\begin{bmatrix} I_{n}&~~ -I_{n}\\ I_{n}&~~ I_{n}\end{bmatrix}. \tag{4}\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

Note that the inverse of $F_{i}$ only needs to be computed once by each edge server because $F_{i}$ is fixed for each edge server.

SECTION V.

## Our Proposed DSOS

### A. Design Rationale

We design a system DSOS about how to securely solve the large-scale OSLE problem based on multiple edge servers. The computation task is delegated to $m$ edge servers that may be lazy, curious and dishonest. To preserve the confidentiality of data, the user can apply two random sparse orthogonal matrices $P_{1}\in \mathbb {R}^{r\times r}$ and $P_{2}\in \mathbb {R}^{n\times n}$ and a random vector $u \in \mathbb {R}^{n\times 1}$ to disguise $A$, $x$, and $b$. Algorithm 2 shows the entire process of outsourcing OSLE.

### Algorithm 2 Distributed Secure Outsourcing System

Input:

$A\in \mathbb {R}^{r\times n}(r > n)$, a constant matrix; $b\in \mathbb {R}^{r \times 1}$, a constant column vector; $x \in \mathbb {R}^{n \times 1} $, an unknown column vector; $m$, the number of edge servers.

Output:

$x\in \mathbb {R}^{n \times 1}$, a least squares solution to $Ax=b$.

- #### Step 1.

  *Key Generation*:

  - The user first chooses a random blinding vector $u \in \mathbb {R}^{n \times 1}$.
  - The user generates two key matrices $P_{1}\in \mathbb {R}^{r \times r}$ and $P_{2}\in \mathbb {R}^{n \times n}$.

  

- #### Step 2.

  *Problem Encryption*:

  - The user calculates: $$\begin{align*} & A'=P_{1}AP_{2}, \\ & y=P^{-1}_{2}(x+u), \\ & b'=P_{1}(b+Au).\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

  

- #### Step 3.

  *Problem Split*:

  - The user divides $A'$ and $b'$ into $m$ blocks according the [equation (3)](https://ieeexplore.ieee.org/document/#deqn3).

  - The user distributes problem parameters $A'_{i}$ and $b'_{i}$ to the corresponding edge servers according to the following rule:

    Send each $A'_{i}$ and $b'_{i}$ to the edge server $i$ and its neighbor servers, where $i \in [1,m]$.

  

- #### Step 4.

  *Problem Solve and Verify*:

  - Each edge server $i$ picks the initial solutions $y_{i}(0)$ and $z_{i}(0)$.

    **for** $k=1$ to $\infty $ **do**

    - Each edge server $i$ computes the intermediate results $y_{i}(k+1)$ and $z_{i}(k+1)$ and sends $M_{i,k+1}=\{y_{i}(k+1),z_{i}(k+1),\{y_{h}(k),z_{h}(k)|h \in \mathcal {N}_{i}\},j\}$ to its neighbor servers.

    - The $i$’s neighbor servers verify the intermediate results $y_{i}(k+1)$ and $z_{i}(k+1)$ according to verification algorithm (Algorithm 3).

    - **if** [equation (5)](https://ieeexplore.ieee.org/document/#deqn5) holds **then**

      Each edge server $i$ returns the final result $y$ to the user.

      **break.**

      **end if**

    

  

- #### Step 5.

  *Result Decryption*:

  - The user calculates: $$\begin{equation*} x=P_{2}y-u.\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)
  - **return** the original result $x$.

  





In the process of generating the key matrix, according to the scale of matrix $A$, the user first generates two permutations $\pi _{1}$ and $\pi _{2}$ by running Algorithm 1. Then, the user can compute each element of the key matrices $P_{1}$ and $P_{2}$ as follows: $$\begin{align*} P_{1}(i,j)=&\alpha _{i}\sigma _{\pi _{1}(i),j},~~ 1\leq i,j\leq r \\ P_{2}(i,j)=&\beta _{i}\sigma _{\pi _{2}(i),j},~~ 1\leq i,j\leq n\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)where $\alpha _{i},\beta _{i} \in \Omega \{1,-1\}$ and $\sigma $ is the Kronecker Delta function.

The user transforms $Ax=b$ into $A'y=b'$. Because the user only needs to perform such as multiplications between the spare matrix and the dense matrix, matrix–vector multiplications and other lightweight operations, the computation complexity on the user side is $O(r^{2})$. Our system DSOS can guarantee the privacy of $A,x$, and $b$ by utilizing the random blinding technique. Then, the user divides $A'$ and $b'$ into $m$ row blocks and distributes them to the corresponding edge servers according to the following rule: $A'_{i}$ and $b'_{i}$ should be sent to the edge server $i$ and its neighbor servers. At the beginning of iterative computation, each edge server $i$ randomly chooses the initial solutions $y_{i}(0)$ and $z_{i}(0)$ (each element in $y_{i}(0)$ and $z_{i}(0)$ is equal to 0). Then, all edge servers begin to carry out iteration process and $i$’s neighbor servers can continuously verify the validity of the intermediate results from the edge server $i$. When the consensus process terminates, all edge servers obtain the final solution $y$, which is the answer to the transformed problem. Then, the user receives $y$ and decrypts it with the key matrices and vector.

The user can set a value $\varepsilon $ to judge whether the consensus process should be terminated. After each iteration, each edge server $i$ computes the following formula to decide whether the consensus process should be terminated: $$\begin{equation*} V(t)=\max \left |{y_{j}(t)-y_{i}(t)}\right |_{2} < \varepsilon, ~~ j\in N_{i} \tag{5}\end{equation*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)where $\varepsilon $ is a threshold set by the user. According to the user’s requirements for accuracy, the user can choose the different values.

In order to ensure the iterative process can keep carrying on and detect the malicious behavior, a verification algorithm should check whether the edge servers carry out their computations according to the distributed consensus algorithm. For example, at iteration $k+1$, the edge server $j$, a neighbor server of edge server $i$, needs to verify the results $y_{i}$ and $z_{i}$ from the edge server $i$. The edge server $j$ needs the knowledge about $A'_{i}$, $b'_{i}$, and the set $\{y_{h}(k),z_{h}(k)|h \in \mathcal {N}_{i} \}$. In the problem split stage, $A_{i}'$ and $b'_{i}$ are distributed to the edge server $i$ and its neighbor servers. So, $F_{i}$ and the inverse of $F_{i}$ can be computed by the neighbor server $j$. In the iterative process, the edge server $i$ only sends $\{y_{h}(k),z_{h}(k)|h \in \mathcal {N}_{i} \}$ to its neighbor servers.

The verification process can be described as follows: at iteration $k+1$, the edge server $i$ broadcasts message $M_{i,k+1}=\{y_{i}(k+1),z_{i}(k+1),\{y_{h}(k),z_{h}(k)|h \in \mathcal {N}_{i}\},j\}$ to its neighbor servers, where $j$ is randomly chosen by the edge server $i$. First, each neighbor server of server $i$ checks the correctness of its $y_{h}(k)$ and $z_{h}(k)$ as follows: for the edge server $h$, an $i$’s neighbor edge server, there are some common neighbor servers ( $\mathcal {N}_{i} \bigcap \mathcal {N}_{h}$) of edge servers $i$ and $h$. First, the edge server $h$ verifies the correctness of $y_{h}(k)$ and $z_{h}(k)$. If verification passes, the results are right and the edge server $i$ is an honest server. If verification does not pass, these common neighbor servers verify the correctness of $y_{h}(k)$ and $z_{h}(k)$ according to $M_{i,k+1}$ and $M_{h,k}$, where $M_{h,k}$ is the broadcasted message by the edge server $h$ at iteration $k$. If more than half of the edge servers can successfully verify, the results are right and the edge server $i$ is an honest server. Otherwise, the results are false and the edge server $i$ is a malicious server. Then, the $i$’s neighbor servers check the correctness of $y_{i}(k+1)$ and $z_{i}(k+1)$ as follows: first, the edge servers $j$ verifies the correctness of results by recomputing $y_{i}(k+1)$ and $z_{i}(k+1)$. If verification passes, the results are right and the edge server $i$ is an honest server. If the results cannot pass verification, then all neighbor servers will recompute $y_{i}(k)$ and $z_{i}(k)$. If more than half of edge servers can successfully pass verification, the results are right. Otherwise, the results are false and the edge server $i$ is a malicious server. We can kick out the malicious edge servers, and restart to distribute and solve the OSLE.

### Algorithm 3 Verification Algorithm

Input:

$M_{i,k+1}$, $M_{h,k}$, where $h$ in $\mathcal {N}_{i}$.

Output:

1 or 0.

1:

The edge server $i$ chooses the edge server $j$ in $\mathcal {N}_{i}$ randomly.

2:

The edge server $i$ sends a message $M_{i,k+1}=\{y_{i}(k+1),z_{i}(k+1),\{y_{h}(k),z_{h}(k)|h \in \mathcal {N}_{i}\},j\}$ to $i'\text{s}$ neighbor servers.

3:

**for** each $h$ in $\mathcal {N}_{i}$ **do**

4:

**if** $h$ successfully verifies $y_{h}(k),z_{h}(k)$ **then**

5:

**continue**

6:

**else if** half of $\mathcal {N}_{i} \bigcap \mathcal {N}_{h}$ successfully verify **then**

7:

**continue**

8:

**else**

9:

**return** 0.

10:

**end if**

11:

**end for**

12:

**if** $j$ successfully verifies $y_{i}(k+1),z_{i}(k+1)$ **then**

13:

**return** 1.

14:

**else if** half of $\mathcal {N}_{i}$ successfully verify **then**

15:

**return** 1.

16:

**else**

17:

**return** 0.

18:

**end if**



In our system, the constant vector $b$ is not disclosed to the edge servers and always kept by the user. Therefore, our system has obvious advantage in solving the different overdetermined linear systems $Ax^{i}=b^{i}$, where the constant vectors $b$ are different but the coefficient matrix $A$ is identical. After the first outsourcing computation, the user only needs to blind the constant vector $b$ and the unknown vector $x$ by using the different vectors $u$. On the other hand, each edge server $i$ can save the matrix $F_{i}^{-1}$ to accelerate the later computation process after the first outsourcing computation.



#### Remark 3:

The neighbors of server $i$ do not need to carry out verification algorithm in each iteration. The user can set a constant value $\alpha $ to reduce the computation burden on each edge server side. Edge servers can only carry out once verification algorithm after $\alpha $ iterations.



Then, we analyze the convergence, correctness, privacy, and efficiency of DSOS in detail.

### B. Convergence Analysis

Each edge server continuously updates its own local solutions by the information from its neighbor servers. Because an iterative method is utilized, it is a must to determine whether and when the iteration will reach a consensus. If there are not the malicious edge servers (the malicious servers are kicked out in process of iterative computation), the convergence of our system, as same as Wang’s system, has been proved in [34]. Moreover, an exponential convergence rate in our system is preferred.

### C. Correctness Analysis



#### Theorem 1:

If the user and the edge servers honestly follow the system DSOS, the corresponding decrypted result $x$ is a least squares solution to $Ax=b$.



#### Proof:

For a least squares solution $x$ to $Ax=b$, we have the equation $A^{T}Ax=A^{T}b$. All edge servers compute and obtain the result $y$ that satisfies ${A'}^{T}A'y={A'}^{T}b'$ $$\begin{align*} {A'}^{T}A'y=&{A'}^{T}b' \\ P_{2}^{T}A^{T}P_{1}^{T}P_{1}AP_{2}P_{2}^{T}y=&P_{2}^{T}A^{T}P_{1}^{T}P_{1}(b+Au) \\ P_{2}^{T}A^{T}A(x+u)=&P_{2}^{T}A^{T}(b+Au) \\ P_{2}^{T}A^{T}Ax+P_{2}^{T}A^{T}Au=&P_{2}^{T}A^{T}b+P_{2}^{T}A^{T}Au \\ P_{2}^{T}A^{T}Ax=&P_{2}^{T}A^{T}b \\ A^{T}Ax=&A^{T}b.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)So, the proposed system is correct.





### D. Privacy Analysis



#### Theorem 2:

The proposed system can protect the privacy of input, that is, the edge servers cannot recover the correct input $(A,b)$ from the encoded input $(A',b')$.



#### Proof:

We first prove the privacy of the key matrices $P_{1}$ and $P_{2}$. Take the key matrix $P_{1}$ as an example. The form of the key matrix $P_{1}$ is as follows: $$\begin{align*} P_{1}=\begin{bmatrix} \alpha _{1}\sigma _{\pi _{1}(1),1} &~~ \cdots &~~ \alpha _{1}\sigma _{\pi _{1}(1),r} \\ \vdots &~~ \ddots &~~ \vdots \\ \alpha _{i}\sigma _{\pi _{1}(i),1}&~~ \cdots &~~ \alpha _{1}\sigma _{\pi _{1}(i),r} \\ \vdots &~~ \ddots &~~ \vdots \\ \alpha _{r}\sigma _{\pi _{1}(r),1}&~~ \cdots &~~ \alpha _{r}\sigma _{\pi _{1}(r),r}\end{bmatrix}.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

First, the adversary needs to guess a random permutation $\pi _{1}$. There are $r!$ possibilities for a random permutation $\pi _{1}$. In addition, the adversary needs to guess each value of $\alpha _{i}$. There are two cases for each $\alpha _{i}$. Therefore, the probability that $P_{1}$ is accurately guessed by the adversary is $[1/(2^{r}r!)]$. Similarly, the probability that $P_{2}$ is accurately guessed by the adversary is $[1/(2^{n}n!)]$.

Then, we analyze the privacy of matrix $A$. The adversary only knows the information of the encrypted matrix $A'$. The matrices $P_{1}$ and $P_{2}$ reorder the matrix $A'$ as follows:

$$\begin{align*} T=&P_{1}A=\begin{bmatrix} \alpha _{1}A_{\pi _{1}(1),1} &~~ \cdots &~~ \alpha _{1}A_{\pi _{1}(1),n} \\ \vdots &~~ \ddots &~~ \vdots \\ \alpha _{i}A_{\pi _{1}(i),1}&~~ \cdots &~~ \alpha _{1}A_{\pi _{1}(i),n} \\ \vdots &~~ \ddots &~~ \vdots \\ \alpha _{r}A_{\pi _{1}(r),1}&~~ \cdots &~~ \alpha _{r}A_{\pi _{1}(r),n}\end{bmatrix} \\ A'=&TP_{2}=\begin{bmatrix} \alpha _{1}\beta _{1}A_{\pi _{1}(1),\pi _{2}(1) } &~~ \cdots &~~ \alpha _{1}\beta _{n}A_{\pi _{1}(1),\pi _{2}(n)} \\ \vdots &~~ \ddots &~~ \vdots \\ \alpha _{i}\beta _{1}A_{\pi _{1}(i),\pi _{2}(1) } &~~ \cdots &~~ \alpha _{i}\beta _{n}A_{\pi _{1}(i),\pi _{2}(n)} \\ \vdots &~~ \ddots &~~ \vdots \\ \alpha _{r}\beta _{1}A_{\pi _{1}(r),\pi _{2}(1) } &~~ \cdots &~~ \alpha _{r}\beta _{n}A_{\pi _{1}(r),\pi _{2}(n)}\end{bmatrix}.\end{align*}$$View Source![Right-click on figure for MathML and additional features.](https://ieeexplore.ieee.org/assets/img/icon.support.gif)

This encryption process consists of two random permutations $\pi _{1}$ and $\pi _{2}$ and the random numbers. It means that there exist $(r!n!)$ cases of permutations. The probability of each case is $[1/(r!n!)]$. Note that $\{\alpha _{1},\ldots, \alpha _{r}\}$ and $\{\beta _{1},\ldots, \beta _{n}\}$ are chosen from the key space $\Omega \{1,-1\}$. It means that there are two kinds of possibility for the term in matrix $A'$. The probability that all elements in the matrix $A'$ can be accurately guessed by the adversary is $[1/(2^{rn}r!n!)]$. In addition, in our system, each edge server can only obtain several blocks about the matrix $A'$, not all matrix $A'$. Without the information about the key matrices and the edge servers collusion, the edge servers cannot recover $A$. As for $b$, we have $b'=P_{1}(b+Au)$. Since $u$ is a random constant vector in $\mathbb {R}^{n\times 1}$ and $P_{1}$ is a random sparse matrix, $b$ is blinded in the sense of indistinguishability.







#### Theorem 3:

The proposed system can protect the privacy of output, that is, based on the encrypted output $y$, the edge servers cannot recover the original output $x$.



#### Proof:

We have $x=P_{2}y-u$. Since $u$ is a random constant vector in $\mathbb {R}^{n\times 1}$ and $P^{-1}_{2}$ is a random sparse matrix, $x$ is blinded in the sense of indistinguishability.





### E. Efficiency Analysis



#### Theorem 4:

The proposed system is an $O(1/r)$-efficient implementation of OSLE.



#### Proof:

The user needs to take $O(r^{2})$ time to carry out multiple matrix–vector multiplications and needs to take $O(r^{2})$ time to compute $A'=P_{1}AP_{2}$ in the proposed system DSOS. In addition, directly solving the OSLE needs to take $O(r^{3})$ time. Thus, the proposed system DSOS is an $(1/r)$-efficient.





We will analyze the computation and communication overhead in detail on the user side and the edge servers side.

#### 1) Computation Overhead Analysis:

Our proposed system DSOS is designed for the IoT devices with the limited computation resources. Compared to solving the OSLE by itself, the computation overhead on the user side in DSOS is much lower. Then, we will give the total computation overhead in the proposed system DSOS for the user and edge servers. The methodology of Salinas *et al.* [28] can be adopted in our efficiency analysis, which defines the computation overhead of an entity as encryptions that the entity performs, bitwise operations and the number of floating-point (flops) operations. In order to briefly describe computation overhead, we define $s$ as the row number of each block $A'_{i}$ and $d$ as the average number of neighbor servers for each edge server. $l$ is denoted as the number of iterations. We define $S$ as the number of bitwise operations for generating a random number [35].

In our system DSOS, generating key, encrypting problem, and decrypting result are all operations that the user needs to conduct. In the key generation, the user first runs Algorithm 1, which needs to take $r+n$ floating-point operations to generate two random permutations $\pi _{1}$ and $\pi _{2}$. Then, generating matrices $P_{1}$ and $P_{2}$ needs to take $r+n$ floating-point operations. The user needs to take $nS$ bitwise operations to obtain $u$. Thus, the overall computation overhead of key generation on the user side is $(2r+2n)\cdot {\mathrm{ flops}} +n\cdot S$. For the problem encryption, the user needs to take $r^{2}+n^{2}$ floating-point operations to compute $A'=P_{1}AP_{2}$. The user needs to carry out $2n$ floating-point operations to obtain $y=P^{-1}_{2}(x+u)$. The user carries out $2rn +r$ floating-point operations to compute $b'=P_{1}(b+Au)$. Thus, the overall computation overhead of problem encryption for the user is $(r^{2}+n^{2}+2rn+2n+r)\cdot {\mathrm{ flops}}$. In the result decryption, the user needs to carry out $2n$ floating-point operations to obtain $x=P_{2}y-u$. To summarize, the total computation overhead on the user side is $(r^{2}+n^{2}+2rn+6n+3r)\cdot {\mathrm{ flops}} +n\cdot S$.

On the edge server side, at the beginning of the iterative computation, each edge server needs to compute $F_{i}^{-1}\,\,d$ times. According to [(4)](https://ieeexplore.ieee.org/document/#deqn4) in Section IV, we see that each edge server takes $s^{2}(2n-1)$ floating-point operations to compute $A_{i}A^{T}_{i}$. Each edge server total needs $s^{2}+2s^{2}n$ floating-point operations to compute $I_{n_{i}}+(1/2d_{i})A_{i}A^{T}_{i}$. In addition, computing $A^{T}_{i}([1/c]I_{n_{i}}+(1/2d_{i})A_{i}A^{T}_{i})^{-1}A_{i}$ needs $(2s-1)n^{2}+(4s^{2}-s)n+s^{2}+s^{3}$ floating-point operations ( $c=1$). In conclusion, each edge server takes $(2s+9)n^{2}+(4s^{2}+6-s)n+s^{2}+s^{3}$ floating-point operations to compute $F_{i}^{-1}$. Note that $s < < t$. In each iteration, each edge server needs to compute the vector in the right of [(4)](https://ieeexplore.ieee.org/document/#deqn4), which takes $(2s+2d-1)n$ floating-point operations. Each edge server needs carry out matrix–vector multiplication, which needs $2n(4n-1)$ floating-point operations. In process of verification, each edge server needs to take $n(8n+2s+2d-3)$ floating-point operations to verify the validity of results from its neighbor servers on average. In each iteration, each edge server needs to decide whether the iterative computation should be terminated, which takes $3(d-1)n$ floating-point operations. Generally speaking, the total computation overhead by deploying our system on the edge server side is $((2s+9)n^{2}+(4s^{2}+6-s)n+s^{2}+s^{3}+l((4s+7d-9)n+8n^{2})) \cdot {\mathrm{ flops}}$.

#### 2) Communication Overhead Analysis:

First, we give an analysis about the communication overhead between each edge server and the user. We denote the size of element in matrix and vector as $E$. The main communication between each edge server and the user is concentrated on distributing the disguised problem. Each edge server not only receives $A'_{i}$ and $b'_{i}$ of itself, but also receives the $A'_{i}$ and $b'_{i}$ of its neighbor servers. We assume that each edge server has $d$ neighbor servers (each edge server is viewed as one neighbor of itself). So, the user needs to transmit $(ds(n+1)) \cdot E$ to one edge server. Then, each edge server needs to transmit $y$ to the user. So, the communication overhead between each edge server and the user is $(ds(n+1)+n) \cdot E$. In other words, the sum of communication overhead between each edge server and the user is $(dr(n+1)+mn) \cdot E$, where $r=m\cdot s $ and the total number of edge servers is $m$.

Then, we give an analysis about the amount of data exchanged between one edge server $i$ and another edge server $j$. In order to keep the iterative computation going on and make its neighbor server $j$ verify the correctness of results, the edge server $i$ needs to send $M_{i,k+1}$ to its neighbor server $j$. The overhead is $(2(d+1)n) \cdot E$. Similarly, the edge server $i$ also needs to receive $M_{j,k+1}$ from the edge server $j$. So, the overhead is $(4(d+1)n) \cdot E$. Therefore, the total communication overhead between two edge servers is $(4l(d+1)n) \cdot E$ after $l$ iterations.

Finally, we analyze the total communication overhead in our system. During the iterative computation, for the edge server $i$, it needs to send $d-1$ messages to its neighbor servers and receive $d-1$ messages from neighbor servers. There are total $m$ edge servers. So, the total communication overhead in our system is $(4ml(d^{2}-1)n+dr(n+1)+mn) \cdot E$.

SECTION VI.

## Performance Evaluation

### A. Experiment Evaluation

We provide some performance evaluations of the proposed system DSOS to demonstrate efficiency. The user is simulated on a computer with Intel Core i5-4210@ 2.6 GHz and 4-GB RAM. The edge server is simulated on a computer with Intel Core i5-6500 @ 3.2 GHz and 8-GB RAM. We implement our proposed system in Python with the NumPy package extension, which can deal with and store the large-scale matrix. In our experiment, the user outsources the OSLE computation task to three edge servers. These servers communicate with each other. As said before, once an edge server behaves maliciously, it will be detected immediately and removed. DSOS will be reexecuted. In our experiments, we assume that the malicious edge servers have been removed in advance and the remaining edge servers will honestly perform computation and verification. The scale of the matrix ranges from $600\times 400$ to $4200\times 4000$.

In the first experiment, we set the threshold $\varepsilon =0.1$ and the scale of matrix from $600\times 400$ to $4200\times 4000$. The time taken by the user in the proposed system DSOS and that of directly solving the OSLE are shown in Fig. 2(a). It reveals the relation between the scale of matrix and the time cost. When the scale of the matrix grows, the time cost also increases. In addition, we can find the time cost taken by the user in our proposed system DSOS is much less than that of directly solving the OSLE because the edge servers have carried out a number of operations.

[![Fig. 2. - Evaluation results for our system DSOS with threshold  $\epsilon =0.1$ . (a) Time cost on the user side. (b) Time cost in different stages. (c) Time cost on the server side. (d) Number of iterations under different matrix scales.](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu2abcd-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu2abcd-3179345-large.gif)

**Fig. 2.**

Evaluation results for our system DSOS with threshold $\epsilon =0.1$. (a) Time cost on the user side. (b) Time cost in different stages. (c) Time cost on the server side. (d) Number of iterations under different matrix scales.

[Show All](https://ieeexplore.ieee.org/document/9791077/figures)



Fig. 2(b) and Table II show the time cost of key generation, problem encryption, and result decryption. As we see from the figure and table, the time cost of result decryption is less than that of key generation and problem encryption. The result decryption requires once matrix–vector multiplication and once vector subtraction. As the scale of matrix increases, the time cost of problem encryption increases faster than that of key generation and result decryption because the problem encryption contains twice matrix–matrix multiplications, twice matrix–vector multiplications, and once vector addition.

**TABLE II** Time Cost Under Different Scales ( )$\epsilon=0.1$

[![Table II-  Time Cost Under Different Scales ( $\epsilon=0.1$ )](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu.t2-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu.t2-3179345-large.gif)



Fig. 2(c) and Table III show the time cost on each server side in the proposed system DSOS and that of solving the OSLE without outsourcing. Note that the time cost on each server side contains computation time and verification time. The time cost on each edge server side in the proposed system DSOS is less than that of directly solving the OSLE. Furthermore, with the scale of the matrix increasing, the acceleration effect on each server side becomes obvious.

**TABLE III** Time Cost Between DSOS and Without Outsourcing ( )$\epsilon=0.1$

[![Table III-  Time Cost Between DSOS and Without Outsourcing ( $\epsilon=0.1$ )](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu.t3-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu.t3-3179345-large.gif)



Fig. 2(d) reveals the relation between the scale of matrix and the number of iterations. With the scale of the matrix growing, the number of iterations also increases. Regardless of the scale of matrix, our system DSOS could approach the correct solution after a certain number of iterative computations.

The second experiment shows the evaluation results for the proposed system DSOS when the scale of matrix and the threshold are different. As we see from Fig. 3(a) and (b), the number of iterations and the time cost on each server side change with the scale of the matrix changing under different threshold $\epsilon $. Fig. 3(c) and (d) shows the number of iterations and the time cost on each server side change with the threshold $\epsilon $ changing under the different scales of matrix.

[![Fig. 3. - Evaluation results for our system DSOS under different conditions. (a) Time cost under different thresholds  $\epsilon $ . (b) Number of iterations under different thresholds  $\epsilon $ . (c) Time cost under the different matrix scales. (d) Number of iterations under different matrix scales.](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu3abcd-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu3abcd-3179345-large.gif)

**Fig. 3.**

Evaluation results for our system DSOS under different conditions. (a) Time cost under different thresholds $\epsilon $. (b) Number of iterations under different thresholds $\epsilon $. (c) Time cost under the different matrix scales. (d) Number of iterations under different matrix scales.

[Show All](https://ieeexplore.ieee.org/document/9791077/figures)



In the third experiment, the scale of matrix is $1200\times 1000$ and the threshold $\epsilon $ ranges from 1 to 0.005. Fig. 4(a) reveals the relation between the threshold $\epsilon $ and the number of iterations. Fig. 4(b) reveals the relation between the time cost on each server side and the threshold $\epsilon $. From these two figures, we know that the time cost and the number of iterations increase when the threshold reduces. In practical application, the user can change the different thresholds $\epsilon $ according to some specific requirements.

[![Fig. 4. - Evaluation results for our system DSOS with the scale of matrix  $m=1200$  and  $n=1000$ . (a) Number of iterations under different thresholds  $\epsilon $ . (b) Time cost under different thresholds  $\epsilon $ .](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu4ab-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu4ab-3179345-large.gif)

**Fig. 4.**

Evaluation results for our system DSOS with the scale of matrix $m=1200$ and $n=1000$. (a) Number of iterations under different thresholds $\epsilon $. (b) Time cost under different thresholds $\epsilon $.

[Show All](https://ieeexplore.ieee.org/document/9791077/figures)



When $\epsilon =0.1$, the time cost on each server side between the first computation and the later computation is shown in Fig. 5. For the different OSLE $Ax^{i}=b^{i}$, the time cost on each server side reduces after the first outsourcing computation.

[![Fig. 5. - Time cost on the server side.](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu5-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu5-3179345-large.gif)

**Fig. 5.**

Time cost on the server side.

[Show All](https://ieeexplore.ieee.org/document/9791077/figures)



### B. Engineering Application

Solving the OSLE problem is very common in area of engineering, such as a smart grid system. With the scale of a smart grid system continuously increasing, the transmission capacity of a smart grid system is getting closer and closer to its operable limit. In addition, because of the interconnection of the regional smart grid system, it becomes more and more prominent to consider the dynamic stability. The low-frequency oscillation problem brings the serious threat to the stability and security of smart grid. Therefore, it is essential to deeply research the inducing mechanism and influencing factors of low-frequency oscillation in smart grid system.

Prony analysis [36] is often used to solve one of the most critical wide-area monitoring applications, namely, the modal estimation of electromechanical oscillations in smart grid system. Prony analysis can deal with some inherently ill-conditioned mathematics. It shows good application prospect in the signal analysis of smart grid system, especially the low-frequency oscillation analysis. Prony algorithm [37] can extract the valuable information from a uniformly sampled signal and decompose a series of exponentially decayed sinusoids.

Fig. 6 shows that a smart grid system contains $M$ senors, which can measure the electrical signals at regular intervals. There are total $N$ measured samples. The user can use these measured values to compute some parameters in a mode by Prony algorithm. In process of computation, the user needs to solve a series of OSLE problems. Due to the high computational complexity, the user can apply DSOS to improve efficiency.

[![Fig. 6. - Application in the smart grid system.](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu6-3179345-small.gif)](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221021/9990979/9791077/yu6-3179345-large.gif)

**Fig. 6.**

Application in the smart grid system.

[Show All](https://ieeexplore.ieee.org/document/9791077/figures)



SECTION VII.

## Conclusion

We put forward a distributed and privacy-preserving outsourcing system DSOS for seeking the least squares solution to the OSLE with the assistance of edge computing. The proposed system can preserve the privacy of input and output by utilizing a special permutation technique. In order to verify the validity of result and detect the malicious behaviors, we designed a novel detection algorithm. We analyzed privacy, efficiency, and verifiability in detail. In addition, the detail experiments showed that the proposed system DSOS is efficient.